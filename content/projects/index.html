---
layout: default
title: Machine Learning Projects
---
<link rel='stylesheet' href='https://use.fontawesome.com/releases/v5.7.0/css/all.css' integrity='sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ' crossorigin='anonymous'>
<style>
	h4 {
		margin-left: 20px;
		color: #1abc9c;
	}
	.project a.main-nav-item {
		text-decoration: none;
	}
	.project a.main-nav-item:hover {
		color: #1abc9c;
		text-decoration: none;
	}
</style>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Markov Chain Monte Carlo(MCMC)</h4>
	<p> Implemented several sampling methods such as rejection sampling, importance sampling, Metropolis-Hastings sampling methods.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Statistical-Learning-STA414/tree/master/sampling" style="display: inline-block">Python code</a>
	<i class='far fa-file' style='margin-left: 45px;color:#999'></i>
	<a class="main-nav-item" href="/pdf/STA414_HW3.pdf" style="display: inline-block">Report</a>
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Naïve Bayes, Logistic Regression, Gaussian Mixtures on MNIST</h4>
	<p> Fitted both generative and discriminative models to the MNIST dataset of handwritten numbers. Implementation has been vectorized.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Statistical-Learning-STA414/tree/master/naive%20bayes:logistic%20regression:gaussian%20mixtures" style="display: inline-block">Python code</a>
	<i class='far fa-file' style='margin-left: 45px;color:#999'></i>
	<a class="main-nav-item" href="/pdf/STA414_HW2.pdf" style="display: inline-block">Report</a> 
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Cross Validation</h4>
	<p> K-fold cross validation procedure to tune the penalty parameter λ in Ridge regression.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Statistical-Learning-STA414/tree/master/cross%20validation" style="display: inline-block">Python code</a>
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Image Completion using Mixture of Bernoullis</h4>
	<p>Implemented a probabilistic model which we can apply to the task of image completion. Basically, we observe the top half of an image of a handwritten digit, and we’d like to predict what’s in the bottom half.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Machine-Learning-CSC411/tree/master/Mixture%20of%20Bernoullis" style="display: inline-block">Python code</a> 
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Gaussian Discriminant Analysis(GDA) to Label Handwritten Digits</h4>
	<p>Each image is 8 by 8 pixels and is represented as a vector
	of dimension 64 by listing all the pixel values in raster scan order. The images are grayscale
	and the pixel values are between 0 and 1. The labels y are 0, 1, 2, · · · , 9 corresponding to
	which character was written in the image. There are 700 training cases and 400 test cases for
	each digit.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Machine-Learning-CSC411/tree/master/GDA" style="display: inline-block">Python code</a>
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Locally Weighted Regression on Boston Housing Dataset</h4>
	<p>Worked with the Boston Housing dataset. This dataset contains 506 entries. Each entry consists of a house price and 13 features for houses within the Boston area.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Machine-Learning-CSC411/tree/master/Locally%20Weighted%20Regression" style="display: inline-block">Python code</a>
</div>
<br>
<div class="project">
	<i class='fas fa-file-alt' style='font-size:24px'></i>
	<h4 style="display: inline-block" >Decision Tree Classifier to Classify Real vs Fake News Headlines</h4>
	<p>Used a dataset of 1298 “fake news” headlines (which mostly include headlines of articles classified as biased, etc.) and 1968 “real” news headlines, where the “fake news” headlines are from https://www.kaggle.com/mrisdal/fake-news/data and “real news” headlines are from https://www.kaggle.com/therohk/million-headlines. The data were cleaned by removing words from fake news titles that are not a part of the headline, removing special characters from the headlines, and restricting real new headlines to those after October 2016 containing the word “trump”.</p>
	<i class='fas fa-terminal' style='color:#999'></i>
	<a class="main-nav-item" href="https://github.com/shin2suka/Machine-Learning-CSC411/tree/master/Decision%20Tree" style="display: inline-block">Python code</a>
</div>
<br>
